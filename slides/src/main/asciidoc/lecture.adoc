= Kafka Streams Testing: A Deep Dive
Ivan Ponomarev, John Roesler
:revealjs_theme: black
:revealjs_customtheme: white_course.css
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images
:source-highlighter: highlightjs
:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false
:revealjs_transition: none
:revealjs_width: 1600
:revealjs_height: 900
:stem: latexmath


//== Часть 1. Введение
:!figure-caption:


== Who Are We

Ivan Ponomarev:

* Software Engineer at KURS, tutor at MIPT
* Apache Kafka Contributor


[.notes]
--
John introduces Ivan
--

== Who Are We

John Roesler:

* Software Engineer at Confluent
* Apache Kafka Committer and PMC member

[.notes]
--
Ivan introduces John
--

== Overview

1. Purpose: cover testing methodologies for Kafka Streams
2. Start with motivating example (from Ivan's production)
3. A flawed testing approach: unit testing doesn't work for this example
4. Deep-dive into the testing framework
5. Correctly testing the example with integration tests

[.notes]
--
John gives an overview of the talk
--

== The task

Save different source IDs in the database

[graphviz,"dedup-problem1.png"]
----
digraph G {
graph [ dpi = 180 ];
rankdir="LR";
A1[label="A"];
B1[label="B"];
A2[label="A"];
B2[label="B"];

A1 -> B1 -> B2 ->A2 ;
DB[shape="cylinder", label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td>A</td>
        <vr/><td>B</td></tr></table>>];
A2->DB;
}
----

[.notes]
--
Ivan: We recieve signals from a number of detectors, and we want to collect all the ID's of detectors that sent something to us at least once.

The signals are being sent to Kafka topic, and we want to pipe them to Redis or any other database. 
--

== The problem

Too many writes to the database

[graphviz,"dedup-problem2.png"]
----
digraph G {
graph [ dpi = 180 ];
rankdir="LR";

A1[label="A"];
B1[label="B"];
A2[label="A"];
B2[label="B"];

A1 -> B1 -> B2 ->A2 ;
DB[shape="cylinder", label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2"><IMG SCALE="BOTH" SRC="slides/src/main/asciidoc/images/worried.png"/></td></tr>
        <tr><td>A</td>
        <vr/><td>B</td></tr></table>>];
A2->DB;


}
----

[.notes]
--
But the problem is that we obtain lots of data from each detector and we don't want to write to the database each time we get an update. 
--


== The solution

Let's deduplicate using Kafka Streams!

[graphviz,"dedup-solution.png"]
----
digraph G {
graph [ dpi = 180 ];
rankdir="LR";
A1[label="A"];
B1[label="B"];
A2[label="A"];
B2[label="B"];

A1 -> B1 -> B2 ->A2 ;

A2->Kafka;

Ad[label="A"];
Bd[label="B"];


Kafka->Ad->Bd->DB;

Kafka[shape="none",label="",
   image="slides/src/main/asciidoc/images/kafka-logo.png"];

DB[shape="cylinder", label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2"><IMG SCALE="BOTH" SRC="slides/src/main/asciidoc/images/smiley.png"/></td></tr>
        <tr><td>A</td>
        <vr/><td>B</td></tr></table>>];
}
----

[.notes]
--
That's why we would like to deduplicate records using Kafka streams before we dump them to the database

Looks like a perfect fit for KStreams - let's write an application!
--

== Demo

1. Spring Boot app
2. Let's do some test-driven development and first write a test
3. Writing a test with TTDriver

[.notes]
--
Ivan is live-coding, John is commenting. 
Test fails because nothing is implemented yet.
Then we turn to slides to discuss what TTD can do

--

== `TopologyTestDriver`

[source,java]
-----
TestInputTopic<String, String> inputTopic =
  topologyTestDriver.createInputTopic(
    INPUT_TOPIC, new StringSerializer(), new StringSerializer());


TestOutputTopic<String, String> outputTopic =
  topologyTestDriver.createOutputTopic(
    OUTPUT_TOPIC, new StringDeserializer(), new StringDeserializer());
-----


== `TopologyTestDriver` capabilities

[cols="30a,35a,35a"]
|===
|What is being sent/received 	
|TestInputTopic methods 	
|TestOutputTopic methods
|A single value 	
|`pipeInput (V)` 	
|`V readValue ()`
|A key/value pair 	
|`pipeInput (K, V)` 	
|`KeyValue<K,V> readKeyValue()`
|===


== `TopologyTestDriver` capabilities

[cols="30a,35a,35a"]
|===
|What is being sent/received 	
|TestInputTopic methods 	
|TestOutputTopic methods
|A list of values 	
|`pipeValueList (List<V>)` 	
|`List<V>
readValuesToList()`
|A list of key/value pairs 	
|`pipeValueList (List<V>)` 	
|`List<KeyValue<K,V>> readKeyValuesToList()`

`Map<K,V> readKeyValuesToMap()`
|A list of Records 	
|`pipeRecordList (List<? extends TestRecord<K, V>>)` 	|`List<TestRecord<K, V>>
readRecordsToList()`
|===


== `TopologyTestDriver` capabilities: Timestamp emulation

[cols="50a,50a"]
|===
|What is being sent 	
|TestInputTopic methods
|A value or a key/value pair with a given timestamp 	|`pipeInput(V, Instant)`

`pipeInput(K, V, Instant)`
|
A value list or a key/value list with a given timestamp for the first record and a time difference between two consecutively generated records
|`pipeValueList (List<V>, Instant, Duration)`

`pipeKeyValueList(List<KeyValue<K, V>>,
                Instant,
                Duration)`
|===

== A "Simple Solution"

[graphviz,"wrong-topology1.png"]
----
digraph G {
graph [ dpi = 180 ];
rankdir="LR";
A1[label="A"];
B1[label="B"];
A2[label="A"];
B2[label="B"];

A1 -> B1 -> B2 ->A2 ;

A2->Reduce;

Reduce[shape=box,label="reduce \n (l, r) → <STOP>"];

Store[shape=cylinder,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Local Store</td></tr>
        <tr><td> </td><td> </td></tr>
        </table>>];

Reduce->Store;

{rank = same; Store; Reduce; }

}
----

[.notes]
--
Ivan: now we need to implement the deduplication

We want to do this as simple as possible and avoid using key-value stores and the Processor API 
--

== A "Simple Solution"

[graphviz,"wrong-topology2.png"]
----
digraph G {
graph [ dpi = 180 ];
rankdir="LR";

A1[label="A"];
B1[label="B"];
A2[label="A"];
B2[label="B"];

A1 -> B1 -> B2 -> Reduce -> A2 ;

Reduce[shape=box,label="reduce \n (l, r) → <STOP>"];

Store[shape=cylinder,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Local Store</td></tr>
        <tr><td>A</td><vr/><td>A</td></tr>
        </table>>];

Reduce->Store;

{rank = same; Store; Reduce; }


}
----

== A "Simple Solution"

[graphviz,"wrong-topology3.png"]
----
digraph G {
graph [ dpi = 180 ];
rankdir="LR";
A1[label="A"];
B1[label="B"];
A2[label="A"];
B2[label="B"];

A1 -> B1 ->  Reduce -> B2 -> A2 ;


Reduce[shape=box,label="reduce \n (l, r) → <STOP>"];

Store[shape=cylinder,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Local Store</td></tr>
        <tr><td>A</td><vr/><td>A</td></tr>
        <tr><td>B</td><vr/><td>B</td></tr>
        </table>>];

Reduce->Store;

{rank = same; Store; Reduce; }

}
----

== A "Simple Solution"

[graphviz,"wrong-topology4.png"]
----
digraph G {
graph [ dpi = 180 ];
rankdir="LR";
A1[label="A"];
B1[label="<STOP>"];
A2[label="A"];
B2[label="B"];

A1 -> Reduce -> B1 -> B2 -> A2 ;

Reduce[shape=box,label="reduce \n (l, r) → <STOP>"]

Store[shape=cylinder,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Local Store</td></tr>
        <tr><td>A</td><vr/><td>A</td></tr>
        <tr><td>B</td><vr/><td>&lt;STOP&gt;</td></tr>
        </table>>];

Reduce->Store;

{rank = same; Store; Reduce; }

}
----

== A "Simple Solution"

[graphviz,"wrong-topology5.png"]
----
digraph G {
graph [ dpi = 180 ];
rankdir="LR";
A1[label="<STOP>"];
B1[label="<STOP>"];
A2[label="A"];
B2[label="B"];

Reduce -> A1 -> B1 -> B2 -> A2 ;

Reduce[shape=box,label="reduce \n (l, r) → <STOP>"]

Store[shape=cylinder,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Local Store</td></tr>
        <tr><td>A</td><vr/><td>&lt;STOP&gt;</td></tr>
        <tr><td>B</td><vr/><td>&lt;STOP&gt;</td></tr>
        </table>>];

Reduce->Store;

{rank = same; Store; Reduce; }

}
----


== Demo

* writing the topology
* TopologyTestDriver test is green

== Should we run this in production?

image::collision.png[]

In production it doesn't work


== Why it's not working

*Kafka Streams* is a big data streaming framework


*TopologyTestDriver* is a fast, deterministic testing framework


== Why it's not working

*Kafka Streams* is a big data streaming framework

* designed for high throughput
* throughput demands batching, buffering, caching, etc.
* caching is the culprit in this example

*TopologyTestDriver* is a fast, deterministic testing framework


== Why it's not working

*Kafka Streams* is a big data streaming framework

* designed for high throughput
* throughput demands batching, buffering, caching, etc.
* caching is the culprit in this example


*TopologyTestDriver* is a fast, deterministic testing framework

* designed for synchronous, immediate results
* flush cache after every update

== Why it's not working

Caching in Kafka Streams

* don't immediately emit every aggregation result
* "soak up" repeated updates to the same key's aggregation
* configure cache size: `max.bytes.buffering` (10MB)
* configure cache flush interval: `commit.interval.ms` (30s)
* emit _latest_ result on flush or eviction

== Why it's not working

[graphviz,"cache1.png"]
----
digraph G {
graph [ dpi = 180 ];
rankdir="LR";
A1[label="A"];
B1[label="B"];
A2[label="A"];
B2[label="B"];

A1 -> B1 -> B2 -> A2 ;

A2->Reduce;

Reduce[shape=box,label="reduce \n (l, r) → <STOP>"]

Reduce -> Cache

Cache[shape=box,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Cache</td></tr>
        <tr><td> </td>
        <td> </td></tr></table>>]
        
Store[shape=cylinder,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Local Store</td></tr>
        <tr><td> </td><td> </td></tr>
        </table>>];
        
Cache -> Store;
{rank = same; Store; Cache; }
}
----


== Why it's not working


[graphviz,"cache1b.png"]
----
digraph G {
graph [ dpi = 180 ];
rankdir="LR";

A1[label="A"];
B1[label="B"];
B2[label="B"];

A1 -> B1 -> B2 -> Reduce;

Reduce[shape=box,label="reduce \n (l, r) → <STOP>"]

Reduce -> Cache

Cache[shape=box,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Cache</td></tr>
        <tr><td>A</td>
        <vr/><td>A</td></tr></table>>];
Store[shape=cylinder,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Local Store</td></tr>
        <tr><td> </td><td> </td></tr>
        </table>>];
        
Cache -> Store;
{rank = same; Store; Cache; }
}
----


== Why it's not working


[graphviz,"cache2.png"]
----
digraph G {
graph [ dpi = 180 ];
rankdir="LR";

A1[label="A"];
B1[label="B"];

A1 -> B1 ->Reduce;

Reduce[shape=box,label="reduce \n (l, r) → <STOP>"];

Reduce -> Cache;

Cache[shape=box,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Cache</td></tr>
        <tr><td>A</td><vr/><td>A</td></tr>
        <tr><td>B</td><vr/><td>B</td></tr>
        </table>>]
Store[shape=cylinder,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Local Store</td></tr>
        <tr><td> </td><td> </td></tr>
        </table>>];
        
Cache -> Store;
{rank = same; Store; Cache; }
}
----


== Why it's not working


[graphviz,"cache2b.png"]
----
digraph G {
graph [ dpi = 180 ];
rankdir="LR";

A1[label="A"];

A1 ->Reduce;

Reduce[shape=box,label="reduce \n (l, r) → <STOP>"]

Reduce -> Cache

Cache[shape=box,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Cache</td></tr>
        <tr><td>A</td><vr/><td>A</td></tr>
        <tr><td>B</td><vr/><td>&lt;STOP&gt;</td></tr>
        </table>>];
Store[shape=cylinder,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Local Store</td></tr>
        <tr><td> </td><td> </td></tr>
        </table>>];
        
Cache -> Store;
{rank = same; Store; Cache; }
}
----



== Why it's not working


[graphviz,"cache3.png"]
----
digraph G {

graph [ dpi = 180 ];
rankdir="LR";

Reduce[shape=box,label="reduce \n (l, r) → <STOP>"];

Reduce -> Cache;

Cache[shape=box,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Cache</td></tr>
        <tr><td>A</td><vr/><td>&lt;STOP&gt;</td></tr>
        <tr><td>B</td><vr/><td>&lt;STOP&gt;</td></tr>
        </table>>]

Store[shape=cylinder,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Local Store</td></tr>
        <tr><td> </td><td> </td></tr>
        </table>>];
        
Cache -> Store;
{rank = same; Store; Cache; }

}
----

== Why it's not working


[graphviz,"cache3b.png"]
----
digraph G {

graph [ dpi = 180 ];
rankdir="LR";
A1[label="<STOP>"];
B1[label="<STOP>"];

Reduce;

Reduce[shape=box,label="reduce \n (l, r) → <STOP>"]

Reduce -> Cache

Cache[shape=box,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Cache</td></tr>
        <tr><td> </td><td> </td></tr>
        </table>>]
Cache -> B1 -> A1;

Store[shape=cylinder,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Local Store</td></tr>
        <tr><td>A</td><vr/><td>&lt;STOP&gt;</td></tr>
        <tr><td>B</td><vr/><td>&lt;STOP&gt;</td></tr>
        </table>>];
        
Cache -> Store;
{rank = same; Store; Cache; }

A1->surprised[style=invis];
{rank = same; A1; surprised; }

surprised[shape="none",label="",
   image="slides/src/main/asciidoc/images/surprised.png"];
}
----

== Demo

TopologyTestDriver vs. Kafka Streams execution loop

== Should we trust StackOverflow?

image::so.png[{image-90-width}]

== Using Transformer

[graphviz,"transformer.png"]
----
digraph G {
graph [ dpi = 180 ];
rankdir="LR";

A1[label="A"];
B1[label="B"];
A2[label="A"];
B2[label="B"];

A1 -> B1 -> Transformer -> B2 -> A2;

Transformer[shape=box,label="ValueTransformerWithKey"];

Transformer -> Cache;

Cache[shape=box,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Cache</td></tr>
        <tr><td>A</td><vr/><td>A</td></tr>
        <tr><td>B</td><vr/><td>B</td></tr>
        </table>>]
Store[shape=cylinder,label=<<table cellspacing="5" cellborder="0"  border="0">
        <tr><td colspan="2">Local Store</td></tr>
        <tr><td> </td><td> </td></tr>
        </table>>];
        
Cache -> Store;

{rank = same; Transformer; Store; Cache; }
}
----

== Let's run tests on real Kafka!

* EmbeddedKafka 

* TestContainers

image::testcontainers.png[{image-30-width}]

== EmbeddedKafka vs TestContainers

[cols="50a,50a"]
|===
|EmbeddedKafka
|TestContainers
|
* Pro:
** Just pull in a dependency
* Contra:
** Pulls in Scala 
** Runs in the same JVM


|
* Pro
** Runs Kafka isolated in Docker
** Not only for Kafka testing
* Contra
** Needs Docker
** Requires some time for the first start
|===

== Demo

* Writing TestContainers test

** An easy part: pushing messages to Kafka
** A not so easy part: how do we check the output?



[.notes]
--
Writing the first attempt (with `poll` inside `while` loop)

This test should be red
--

== Demo

* Deduplication: the correct implementation

* Now the test is green, but takes 5 seconds!

[.notes]
--
This should be copy-pasted from Confluent tutorials
TODO: add graphics explaining the working principle
--

== Does it have to be so slow?

[source,java]
-----
List actual = new ArrayList<>();

while (true) {
  ConsumerRecords<String, String> records =
    KafkaTestUtils.getRecords(consumer, 5000 /* timeout in ms */);
  if (records.isEmpty()) break;
  for (ConsumerRecord<String, String> rec : records) {
    actual.add(rec.value());
  }
}
  
assertEquals(List.of("A", "B"), actual);
-----

== Awaitility

[source,java]
-----
Awaitility.await().atMost(10, SECONDS).until(
         	() -> List.of("A", "B",).equals(actual));
-----

[plantuml, awaitility-pass, png]
----
@startuml
!pragma teoz true
skinparam dpi 180
hide footbox
-> Awaitility: until
activate Awaitility
{start} Awaitility -> conditionEvaluator: call                                               .
conditionEvaluator --> Awaitility: false
...

Awaitility -> conditionEvaluator: call
{end} conditionEvaluator --> Awaitility: **true**
{start} <-> {end} : < 10 s
<-- Awaitility
deactivate Awaitility
@enduml
----

== Awaitility

[source,java]
-----
Awaitility.await().atMost(10, SECONDS).until(
         	() -> List.of("A", "B",).equals(actual));
-----
[plantuml, awaitility-fail, png]
----
@startuml
!pragma teoz true
skinparam dpi 180
hide footbox
-> Awaitility: until
activate Awaitility
{start} Awaitility -> conditionEvaluator: call                                               .
conditionEvaluator --> Awaitility: false
...

Awaitility -> conditionEvaluator: call
{end} conditionEvaluator --> Awaitility: **false**
{start} <-> {end} : > 10 s
[x<-- Awaitility: ConditionTimeoutException
deactivate Awaitility
@enduml
----


== Things we must keep in mind

* Cooperative termination
* Thread-safe data structure

== Demo

* Green test runs faster

== Will any extra messages appear?

* We can wait for extra 5 seconds (bad choice)
* We can put a 'marker record' at the end of the input and wait for it to appear in the output (not always possible)  

== KIP-655 is under discussion

image::kip-655.png[{image-80-width}]

== Summary

[%step]
* TopologyTestDriver is a required tool
* But it doesn't fully reflect all aspects of real Kafka cluster
* Integration tests are 'real', but asynchronous
